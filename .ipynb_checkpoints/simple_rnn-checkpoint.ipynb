{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"data/alice.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Файл содержит символы конца строки и символы не в кодировке ascii, поэтому предварительно обработаем\n",
    "\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку RNN будет предсказывать символы, то и словарь состоит из множества символов, встречающихся в тексте. Таких 42. Но работать будем не с самими символами, а с их индексами, поэтому создадим таблицы соответствия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим последовательность входных строк и меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   The sky wa -> s\n",
    "#   he sky was ->  \n",
    "#   e sky was  -> f\n",
    "#    sky was f -> a\n",
    "#   sky was fa -> l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gu', 'roject gut', 'oject gute', 'ject guten', 'ect gutenb']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'e', 'n', 'b', 'e']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_chars[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг – векторизация входных строк и меток. На вход RNN подаются построенные строки. В каждой из них SEQLEN символов, а поскольку размер нашего словаря составляет nb_char символов, то каждый входной символ представляется унитарным вектором длины nb_chars.  Следовательно каждый входной элемент представляет собой тензор формы SEQLEN x nb_chars. Выходная метка – единственный символ, то есть вектор длины nb_chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars))\n",
    "y = np.zeros((len(input_chars), nb_chars))\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размерность выхода RNN будет равна 128. Это гиперпараметр. Мы ходим получить на выходе один символ, а не последовательнгость, поэтому задаем параметр return_sequences=False. РНС соединяется с плотным слоем. В плотном слое nb_char нейронов, которые выдают оценки появления каждого символа из словаря. Символ с наибольшгей вероятностью возвращается в качестве предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_chars),\n",
    "                    unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы обучали модель в течение какого то числа периодов, а затем оценивали  на тестовых данных. Мы выполняем 25 периодов обучения и тестируем модель после каждого периода. Тестирование производится так – модель порождает символ по заданным входным данным, затем первый символ входной строки отбрасывается, в конец дописывается предсказанный на предыдущем прогоне символ и у модели запрашивается следующее предсказание. Так повторяется 100 раз NUM_PREDS_PER_EPOCH, после чего получившаяся строка печатается. Эта строка и является индикатором качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 42us/step - loss: 2.3401\n",
      "Generating from seed: uld have c\n",
      "uld have could and the said the couthe would the said the couthe would the said the couthe would the said the \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 33us/step - loss: 2.0438\n",
      "Generating from seed: rements, w\n",
      "rements, whe said the harked and the said the harked and the said the harked and the said the harked and the s\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 31us/step - loss: 1.9376\n",
      "Generating from seed: asleep, he\n",
      "asleep, her all the she said the said the said the said the said the said the said the said the said the said \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 31us/step - loss: 1.8582\n",
      "Generating from seed: n on their\n",
      "n on their was in the doon the mad the king to the groplong to the groplong to the groplong to the groplong to\n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.7944\n",
      "Generating from seed: re was gen\n",
      "re was gene beras on the project gutenberg-tm alice said the dormouse the sard the was the was the was the was\n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.7409\n",
      "Generating from seed: aid alice \n",
      "aid alice to her one the onter see to see the onter see to see the onter see to see the onter see to see the o\n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.6957\n",
      "Generating from seed: e had got \n",
      "e had got the white read and the the was the white read and the the was the white read and the the was the whi\n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.6569\n",
      "Generating from seed: gs--i cant\n",
      "gs--i cant the mouse for she had not of the could not and the sarted to the sard all of courd and the mork the\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.6224\n",
      "Generating from seed: hing; so i\n",
      "hing; so its and the project gutenberg-tm electronic work the project gutenberg-tm electronic work the project\n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.5944\n",
      "Generating from seed:  a dispute\n",
      " a disputed to herself it was a little be the courted to herself it was a little be the courted to herself it \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.5694\n",
      "Generating from seed: ought alic\n",
      "ought alice the dormouse to see the courd and the the courd and the the courd and the the courd and the the co\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.5477\n",
      "Generating from seed: you by the\n",
      "you by the said the dormouse so there were the dormouse so there were the dormouse so there were the dormouse \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.5274\n",
      "Generating from seed: aking such\n",
      "aking such a dond the mock turtle she was a the march hare was she was a the march hare was she was a the marc\n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 5s 32us/step - loss: 1.5116\n",
      "Generating from seed: h which th\n",
      "h which the parton and the pabbit was so the poor all the parton and the pabbit was so the poor all the parton\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 35us/step - loss: 1.4944\n",
      "Generating from seed: a cat may \n",
      "a cat may with the caterpillar the she she said the moment the mouse some of the come of the come of the come \n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 39us/step - loss: 1.4814\n",
      "Generating from seed: to another\n",
      "to another all her head to the project gutenberg-tm not the project gutenberg-tm not the project gutenberg-tm \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4685\n",
      "Generating from seed: hers. we m\n",
      "hers. we mand alice the mock turtle she was a little that she was a little that she was a little that she was \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4571\n",
      "Generating from seed: -just befo\n",
      "-just before the dormouse the dormouse the dormouse the dormouse the dormouse the dormouse the dormouse the do\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4470\n",
      "Generating from seed:  queen add\n",
      " queen add the childer as she could the caterpillar. alice thing to her fith the courter that she was a look o\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4377\n",
      "Generating from seed: looked at \n",
      "looked at the beg thing alice was a long have you had all the time the mock turtle she was a little began the \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4284\n",
      "Generating from seed: ed tone: t\n",
      "ed tone: the reased and a great deap note tried the gryphon. the mock turtle some with a long to the gryphon. \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4213\n",
      "Generating from seed: e voluntee\n",
      "e volunteed, that she said the caterpillar that she said the caterpillar that she said the caterpillar that sh\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 39us/step - loss: 1.4122\n",
      "Generating from seed: , what am \n",
      ", what am it was the dident to see it was to her hand at the project gutenberg-tm electronic work alice look o\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4062\n",
      "Generating from seed: ng its tai\n",
      "ng its tain alice thought alice thought alice thought alice thought alice thought alice thought alice thought \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.3998\n",
      "Generating from seed: n. alice t\n",
      "n. alice thought alice, and she had near the hatter said the hatter said the hatter said the hatter said the h\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это пример типа многие-ко-многим - все входные последовательности имеют одинаковую длину, а выход порождается на каждом временном шаге."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
